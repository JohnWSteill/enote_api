{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a604b386",
   "metadata": {},
   "source": [
    "# Corpus Exploration\n",
    "\n",
    "Interactive exploration of the Corpus class for development and testing.\n",
    "Use this notebook to experiment with the ENEX parsing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bac20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Import successful! Workspace settings are working.\n"
     ]
    }
   ],
   "source": [
    "# Test if workspace settings handle the import path\n",
    "# If this fails, we'll need to add back the sys.path.insert() \n",
    "\n",
    "import enote\n",
    "\n",
    "print(\"‚úÖ Import successful! Workspace settings are working.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "061ee6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus attributes:\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__firstlineno__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__static_attributes__', '__str__', '__subclasshook__', '__weakref__', '_clean_enml', '_generate_note_id', '_parse_note_element', 'enex_path', 'export_for_rag', 'get_backlinks', 'get_linked_notes', 'load', 'notes', 'query']\n"
     ]
    }
   ],
   "source": [
    "# Explore the Corpus class\n",
    "corpus = enote.Corpus()\n",
    "print(\"Corpus attributes:\")\n",
    "print(dir(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c30b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method load in module enote.corpus:\n",
      "\n",
      "load(max_notes: Optional[int] = None) -> None method of enote.corpus.Corpus instance\n",
      "    Load and parse notes from ENEX files into the corpus.\n",
      "\n",
      "    Args:\n",
      "        max_notes: Optional limit on number of notes to load\n",
      "                  (useful for testing with large datasets)\n",
      "\n",
      "    Note:\n",
      "        Populates self.notes with the parsed note data.\n",
      "        Each note is stored as: note_id -> {title, body, tags, metadata}\n",
      "\n",
      "    Example:\n",
      "        {\n",
      "            \"note_123\": {\n",
      "                \"title\": \"Project Ideas\",\n",
      "                \"body\": \"...\",\n",
      "                \"tags\": [\"projects\", \"brainstorm\"],\n",
      "                \"created\": datetime(...),\n",
      "                \"updated\": datetime(...)\n",
      "            }\n",
      "        }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at the documentation\n",
    "help(corpus.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0062302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 notes\n"
     ]
    }
   ],
   "source": [
    "# Load some notes and explore\n",
    "corpus.load(max_notes=2)\n",
    "print(f\"Loaded {len(corpus.notes)} notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85da4aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== band_practice_checklist ===\n",
      "Title: Band Practice checklist\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnote_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTitle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnote_data[\u001b[33m'\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTags: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnote_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKeys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(note_data.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Just show first one\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'tags'"
     ]
    }
   ],
   "source": [
    "# Explore the notes structure\n",
    "for note_id, note_data in corpus.notes.items():\n",
    "    print(f\"\\n=== {note_id} ===\")\n",
    "    print(f\"Title: {note_data['title']}\")\n",
    "    print(f\"Tags: {note_data['tags']}\")\n",
    "    print(f\"Keys: {list(note_data.keys())}\")\n",
    "    break  # Just show first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2adb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some operations\n",
    "first_note = list(corpus.notes.values())[0]\n",
    "print(\"First note structure:\")\n",
    "for key, value in first_note.items():\n",
    "    print(f\"{key}: {type(value)} - {str(value)[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new cleaned_text functionality\n",
    "for note_id, note_data in corpus.notes.items():\n",
    "    original = note_data.get('content', '')\n",
    "    cleaned = note_data.get('cleaned_text', '')\n",
    "    \n",
    "    print(f\"\\n=== {note_id}: {note_data['title']} ===\")\n",
    "    print(f\"Original length: {len(original)} chars\")\n",
    "    print(f\"Cleaned length: {len(cleaned)} chars\")\n",
    "    \n",
    "    if len(original) > 0:\n",
    "        reduction = ((len(original) - len(cleaned)) / len(original)) * 100\n",
    "        print(f\"Size reduction: {reduction:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nCleaned text preview:\")\n",
    "    print(cleaned[:200] + \"...\" if len(cleaned) > 200 else cleaned)\n",
    "    \n",
    "    break  # Just show first one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2f9eb",
   "metadata": {},
   "source": [
    "## RAG Export\n",
    "\n",
    "Test the new RAG export functionality. This generates JSON in the standard format for feeding into LLMs and vector databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG export with a small sample first\n",
    "print(\"=== Testing RAG Export (Small Sample) ===\")\n",
    "\n",
    "# Create a fresh corpus for export testing\n",
    "export_corpus = enote.Corpus()\n",
    "export_corpus.load(max_notes=3)  # Just a few notes for testing\n",
    "\n",
    "print(f\"Loaded {len(export_corpus.notes)} notes for export test\")\n",
    "\n",
    "# Export to string (not file) for preview\n",
    "rag_json = export_corpus.export_for_rag()\n",
    "\n",
    "# Show the structure\n",
    "import json\n",
    "rag_data = json.loads(rag_json)\n",
    "\n",
    "print(f\"\\nFirst exported entry:\")\n",
    "print(json.dumps(rag_data[0], indent=2))\n",
    "\n",
    "print(f\"\\nNote IDs in export:\")\n",
    "for item in rag_data:\n",
    "    print(f\"  - {item['id']}: {item['metadata']['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b73c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full export (uncomment when you want to export all notes)\n",
    "# WARNING: This loads ALL notes and creates a large JSON file\n",
    "\n",
    "def export_all_notes():\n",
    "    \"\"\"Export all notes to RAG format JSON file.\"\"\"\n",
    "    print(\"=== Exporting ALL Notes to RAG Format ===\")\n",
    "    \n",
    "    corpus = enote.Corpus()\n",
    "    print(f\"Loading notes from: {corpus.enex_path}\")\n",
    "    \n",
    "    # Load all notes (no max_notes limit)\n",
    "    corpus.load()\n",
    "    print(f\"Loaded {len(corpus.notes)} notes\")\n",
    "    \n",
    "    # Export to Desktop for safety (avoid accidentally committing private data)\n",
    "    from pathlib import Path\n",
    "    desktop_path = Path.home() / \"Desktop\"\n",
    "    output_file = desktop_path / \"evernote_rag_export.json\"\n",
    "    \n",
    "    corpus.export_for_rag(str(output_file))\n",
    "    \n",
    "    print(f\"‚úÖ Exported to {output_file}\")\n",
    "    print(f\"üîí Safely stored outside project directory\")\n",
    "    \n",
    "    file_size_kb = output_file.stat().st_size / 1024\n",
    "    print(f\"üìä File size: {file_size_kb:.1f} KB\")\n",
    "    \n",
    "    # Show sample of what was exported\n",
    "    print(f\"\\nSample note IDs:\")\n",
    "    for i, note_id in enumerate(list(corpus.notes.keys())[:5]):\n",
    "        print(f\"  {i+1}. {note_id}\")\n",
    "    \n",
    "    if len(corpus.notes) > 5:\n",
    "        print(f\"  ... and {len(corpus.notes) - 5} more\")\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "# Uncomment the line below when you want to do the full export:\n",
    "# full_corpus = export_all_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the exported JSON structure\n",
    "def analyze_rag_export(json_file=None):\n",
    "    \"\"\"Analyze the structure and content of the RAG export.\"\"\"\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "    \n",
    "    # Default to Desktop location for safety\n",
    "    if json_file is None:\n",
    "        json_file = Path.home() / \"Desktop\" / \"evernote_rag_export.json\"\n",
    "    else:\n",
    "        json_file = Path(json_file)\n",
    "    \n",
    "    if not json_file.exists():\n",
    "        print(f\"‚ùå File {json_file} not found. Run export_all_notes() first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"=== Analyzing {json_file.name} ===\")\n",
    "    \n",
    "    # Load and analyze\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"üìä Total notes: {len(data)}\")\n",
    "    \n",
    "    # Analyze text lengths\n",
    "    text_lengths = [len(item['text']) for item in data]\n",
    "    print(f\"üìù Text length stats:\")\n",
    "    print(f\"  - Average: {sum(text_lengths) / len(text_lengths):.0f} chars\")\n",
    "    print(f\"  - Shortest: {min(text_lengths)} chars\")\n",
    "    print(f\"  - Longest: {max(text_lengths)} chars\")\n",
    "    \n",
    "    # Analyze tags\n",
    "    all_tags = []\n",
    "    for item in data:\n",
    "        tags = item['metadata']['tags']\n",
    "        if isinstance(tags, list):\n",
    "            all_tags.extend(tags)\n",
    "        elif tags:  # single tag as string\n",
    "            all_tags.append(tags)\n",
    "    \n",
    "    unique_tags = set(all_tags)\n",
    "    print(f\"üè∑Ô∏è  Tag stats:\")\n",
    "    print(f\"  - Total tag instances: {len(all_tags)}\")\n",
    "    print(f\"  - Unique tags: {len(unique_tags)}\")\n",
    "    \n",
    "    # Show sample entries with different characteristics\n",
    "    print(f\"\\nSample entries:\")\n",
    "    print(f\"1. Shortest note: {min(data, key=lambda x: len(x['text']))['id']}\")\n",
    "    print(f\"2. Longest note: {max(data, key=lambda x: len(x['text']))['id']}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Uncomment to analyze after export:\n",
    "# analysis = analyze_rag_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VS_Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
