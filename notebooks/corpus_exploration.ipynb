{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a604b386",
   "metadata": {},
   "source": [
    "# Corpus Exploration\n",
    "\n",
    "Interactive exploration of the Corpus class for development and testing.\n",
    "Use this notebook to experiment with the ENEX parsing functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac20a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh setup - clear all imports and restart\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Print working directory to debug\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Clear any cached modules\n",
    "modules_to_clear = [mod for mod in sys.modules if mod.startswith('enote')]\n",
    "for mod in modules_to_clear:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "# Set correct path\n",
    "project_root = os.path.abspath('..')\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "print(f\"Adding to path: {src_path}\")\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Import fresh\n",
    "import enote\n",
    "print(f\"Imported enote from: {enote.__file__}\")\n",
    "print(f\"Corpus module: {enote.corpus.__file__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ee6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test corpus with fresh imports\n",
    "corpus = enote.Corpus()\n",
    "corpus.load(max_notes=3)\n",
    "\n",
    "print(f\"Loaded {len(corpus.notes)} notes\")\n",
    "\n",
    "# Test each note\n",
    "for note_id, note_data in corpus.notes.items():\n",
    "    print(f\"\\n=== {note_id} ===\")\n",
    "    print(f\"Title: {note_data['title']}\")\n",
    "    print(f\"Available keys: {list(note_data.keys())}\")\n",
    "    \n",
    "    # Check the tags field\n",
    "    if 'tags' in note_data:\n",
    "        tags = note_data['tags']\n",
    "        print(f\"Tags: {tags} (type: {type(tags)}, length: {len(tags) if isinstance(tags, list) else 'not a list'})\")\n",
    "        \n",
    "        # Verify it's always a list\n",
    "        if isinstance(tags, list):\n",
    "            print(f\"✅ Tags is a list as expected\")\n",
    "            if len(tags) > 0:\n",
    "                print(f\"First tag: '{tags[0]}'\")\n",
    "        else:\n",
    "            print(f\"❌ Tags is not a list: {type(tags)}\")\n",
    "    else:\n",
    "        print(\"❌ No 'tags' field found\")\n",
    "    \n",
    "    # Check if old 'tag' field still exists\n",
    "    if 'tag' in note_data:\n",
    "        print(f\"❌ Old 'tag' field still present: {note_data['tag']}\")\n",
    "    else:\n",
    "        print(\"✅ Old 'tag' field properly removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG export with corrected tags field\n",
    "import json\n",
    "\n",
    "rag_json = corpus.export_for_rag()\n",
    "rag_data = json.loads(rag_json)\n",
    "\n",
    "print(f\"Exported {len(rag_data)} notes for RAG\")\n",
    "print(f\"First note structure:\")\n",
    "\n",
    "first_note = rag_data[0]\n",
    "print(json.dumps(first_note, indent=2))\n",
    "\n",
    "# Verify tags are always lists in export\n",
    "print(f\"\\nTags verification:\")\n",
    "for i, note in enumerate(rag_data):\n",
    "    tags = note['metadata']['tags']\n",
    "    if isinstance(tags, list):\n",
    "        print(f\"Note {i+1}: ✅ tags is list with {len(tags)} items: {tags}\")\n",
    "    else:\n",
    "        print(f\"Note {i+1}: ❌ tags is not list: {type(tags)} = {tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some notes and explore\n",
    "corpus.load(max_notes=2)\n",
    "print(f\"Loaded {len(corpus.notes)} notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart kernel to pick up latest code changes\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "import enote\n",
    "\n",
    "# Create corpus and load notes\n",
    "corpus = enote.Corpus()\n",
    "corpus.load(max_notes=10)\n",
    "\n",
    "print(f\"Loaded {len(corpus.notes)} notes\")\n",
    "\n",
    "# Test the tags field\n",
    "for note_id, note_data in corpus.notes.items():\n",
    "    print(f\"=== {note_id} ===\")\n",
    "    print(f\"Title: {note_data['title']}\")\n",
    "    print(f\"Available keys: {list(note_data.keys())}\")\n",
    "    \n",
    "    # Check both possible tag fields\n",
    "    if 'tags' in note_data:\n",
    "        print(f\"Tags field: {note_data['tags']} (type: {type(note_data['tags'])})\")\n",
    "    if 'tag' in note_data:\n",
    "        print(f\"Tag field: {note_data['tag']} (type: {type(note_data['tag'])})\")\n",
    "    \n",
    "    break  # Just show first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2adb674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some operations\n",
    "first_note = list(corpus.notes.values())[0]\n",
    "print(\"First note structure:\")\n",
    "for key, value in first_note.items():\n",
    "    print(f\"{key}: {type(value)} - {str(value)[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new cleaned_text functionality\n",
    "for note_id, note_data in corpus.notes.items():\n",
    "    original = note_data.get('content', '')\n",
    "    cleaned = note_data.get('cleaned_text', '')\n",
    "    \n",
    "    print(f\"\\n=== {note_id}: {note_data['title']} ===\")\n",
    "    print(f\"Original length: {len(original)} chars\")\n",
    "    print(f\"Cleaned length: {len(cleaned)} chars\")\n",
    "    \n",
    "    if len(original) > 0:\n",
    "        reduction = ((len(original) - len(cleaned)) / len(original)) * 100\n",
    "        print(f\"Size reduction: {reduction:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nCleaned text preview:\")\n",
    "    print(cleaned[:200] + \"...\" if len(cleaned) > 200 else cleaned)\n",
    "    \n",
    "    break  # Just show first one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2f9eb",
   "metadata": {},
   "source": [
    "## RAG Export\n",
    "\n",
    "Test the new RAG export functionality. This generates JSON in the standard format for feeding into LLMs and vector databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG export with a small sample first\n",
    "print(\"=== Testing RAG Export (Small Sample) ===\")\n",
    "\n",
    "# Create a fresh corpus for export testing\n",
    "export_corpus = enote.Corpus()\n",
    "export_corpus.load(max_notes=3)  # Just a few notes for testing\n",
    "\n",
    "print(f\"Loaded {len(export_corpus.notes)} notes for export test\")\n",
    "\n",
    "# Export to string (not file) for preview\n",
    "rag_json = export_corpus.export_for_rag()\n",
    "\n",
    "# Show the structure\n",
    "import json\n",
    "rag_data = json.loads(rag_json)\n",
    "\n",
    "print(f\"\\nFirst exported entry:\")\n",
    "print(json.dumps(rag_data[0], indent=2))\n",
    "\n",
    "print(f\"\\nNote IDs in export:\")\n",
    "for item in rag_data:\n",
    "    print(f\"  - {item['id']}: {item['metadata']['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b73c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full export (uncomment when you want to export all notes)\n",
    "# WARNING: This loads ALL notes and creates a large JSON file\n",
    "\n",
    "def export_all_notes():\n",
    "    \"\"\"Export all notes to RAG format JSON file.\"\"\"\n",
    "    print(\"=== Exporting ALL Notes to RAG Format ===\")\n",
    "    \n",
    "    corpus = enote.Corpus()\n",
    "    print(f\"Loading notes from: {corpus.enex_path}\")\n",
    "    \n",
    "    # Load all notes (no max_notes limit)\n",
    "    corpus.load()\n",
    "    print(f\"Loaded {len(corpus.notes)} notes\")\n",
    "    \n",
    "    # Export to Desktop for safety (avoid accidentally committing private data)\n",
    "    from pathlib import Path\n",
    "    desktop_path = Path.home() / \"Desktop\"\n",
    "    output_file = desktop_path / \"evernote_rag_export.json\"\n",
    "    \n",
    "    corpus.export_for_rag(str(output_file))\n",
    "    \n",
    "    print(f\"✅ Exported to {output_file}\")\n",
    "    print(f\"🔒 Safely stored outside project directory\")\n",
    "    \n",
    "    file_size_kb = output_file.stat().st_size / 1024\n",
    "    print(f\"📊 File size: {file_size_kb:.1f} KB\")\n",
    "    \n",
    "    # Show sample of what was exported\n",
    "    print(f\"\\nSample note IDs:\")\n",
    "    for i, note_id in enumerate(list(corpus.notes.keys())[:5]):\n",
    "        print(f\"  {i+1}. {note_id}\")\n",
    "    \n",
    "    if len(corpus.notes) > 5:\n",
    "        print(f\"  ... and {len(corpus.notes) - 5} more\")\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "# Uncomment the line below when you want to do the full export:\n",
    "# full_corpus = export_all_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the exported JSON structure\n",
    "def analyze_rag_export(json_file=None):\n",
    "    \"\"\"Analyze the structure and content of the RAG export.\"\"\"\n",
    "    from pathlib import Path\n",
    "    import json\n",
    "    \n",
    "    # Default to Desktop location for safety\n",
    "    if json_file is None:\n",
    "        json_file = Path.home() / \"Desktop\" / \"evernote_rag_export.json\"\n",
    "    else:\n",
    "        json_file = Path(json_file)\n",
    "    \n",
    "    if not json_file.exists():\n",
    "        print(f\"❌ File {json_file} not found. Run export_all_notes() first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"=== Analyzing {json_file.name} ===\")\n",
    "    \n",
    "    # Load and analyze\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"📊 Total notes: {len(data)}\")\n",
    "    \n",
    "    # Analyze text lengths\n",
    "    text_lengths = [len(item['text']) for item in data]\n",
    "    print(f\"📝 Text length stats:\")\n",
    "    print(f\"  - Average: {sum(text_lengths) / len(text_lengths):.0f} chars\")\n",
    "    print(f\"  - Shortest: {min(text_lengths)} chars\")\n",
    "    print(f\"  - Longest: {max(text_lengths)} chars\")\n",
    "    \n",
    "    # Analyze tags\n",
    "    all_tags = []\n",
    "    for item in data:\n",
    "        tags = item['metadata']['tags']\n",
    "        if isinstance(tags, list):\n",
    "            all_tags.extend(tags)\n",
    "        elif tags:  # single tag as string\n",
    "            all_tags.append(tags)\n",
    "    \n",
    "    unique_tags = set(all_tags)\n",
    "    print(f\"🏷️  Tag stats:\")\n",
    "    print(f\"  - Total tag instances: {len(all_tags)}\")\n",
    "    print(f\"  - Unique tags: {len(unique_tags)}\")\n",
    "    \n",
    "    # Show sample entries with different characteristics\n",
    "    print(f\"\\nSample entries:\")\n",
    "    print(f\"1. Shortest note: {min(data, key=lambda x: len(x['text']))['id']}\")\n",
    "    print(f\"2. Longest note: {max(data, key=lambda x: len(x['text']))['id']}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Uncomment to analyze after export:\n",
    "# analysis = analyze_rag_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that tags normalization fixes the bug\n",
    "print(\"=== Testing Tags Normalization ===\")\n",
    "\n",
    "test_corpus = enote.Corpus()\n",
    "test_corpus.load(max_notes=10)  # Load more notes to find edge cases\n",
    "\n",
    "notes_without_original_tags = 0\n",
    "for note_id, note_data in test_corpus.notes.items():\n",
    "    # Check that every note now has tags (even if empty)\n",
    "    assert 'tags' in note_data, f\"Note {note_id} missing tags field!\"\n",
    "    assert 'tag' in note_data, f\"Note {note_id} missing tag field!\"\n",
    "    assert isinstance(note_data['tags'], list), f\"Note {note_id} tags not a list!\"\n",
    "    \n",
    "    # Count notes that originally had no tags\n",
    "    if len(note_data['tags']) == 0:\n",
    "        notes_without_original_tags += 1\n",
    "\n",
    "print(f\"✅ All {len(test_corpus.notes)} notes have normalized tags\")\n",
    "print(f\"📊 Notes with no tags: {notes_without_original_tags}\")\n",
    "print(f\"📊 Notes with tags: {len(test_corpus.notes) - notes_without_original_tags}\")\n",
    "\n",
    "# Show examples\n",
    "print(f\"\\nTag examples:\")\n",
    "for i, (note_id, note_data) in enumerate(test_corpus.notes.items()):\n",
    "    if i >= 3:  # Just show first 3\n",
    "        break\n",
    "    tags = note_data['tags']\n",
    "    title = note_data['title']\n",
    "    print(f\"  {note_id}: {len(tags)} tags - {tags} ('{title}')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VS_Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
